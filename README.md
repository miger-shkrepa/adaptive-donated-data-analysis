This repository is based on work originally created by [Jonathan Decker](https://gitlab-ce.gwdg.de/hpc-team-public/chat-ai-llamaindex-examples).

# ChatAI LlamaIndex Examples

This repository contains an example implementation of a minimal RAG application using LlamaIndex and the [Chat AI API](https://kisski.gwdg.de/leistungen/2-02-llm-service/).

Most notably it contains an implementation of vllm_embeddings to enable using the OpenAI like embeddings API of ChatAI, which runs via vLLM in the backend.

## Getting Started

The dependencies are managed via [poetry](https://github.com/python-poetry/poetry) and are set to use Python 3.12. but should also work with older Python versions.

```bash
git clone https://gitlab-ce.gwdg.de/hpc-team/chat-ai-llamaindex-examples
cd chatai-llamaindex-examples
poetry install --no-root

cp .env.example .env
# Add your ChatAI API key to .env

poetry shell
# Run pytest to verify that the API access is working
pytest
# Run the minimal example
python main.py
```

The files to be used for the RAG-enhanced generation are to be placed in the [data](data) folder.

## Master Thesis Experiment Orientation

- The experiments (scripts) conducted in this study are located in the [experiments](experiments) folder.
- The results of each experiment are stored in the [results](results) folder.
- The scripts for processing results and the notebooks for visualizing them are in the [processing](processing) folder.
- The scripts used to generate ground truths for each data package are in the [get_ground_truths](ground_truths/get_ground_truths) folder.
- All executable scripts generated by the LLMs in each experiment can be found in the [executed_scripts](generated_code/executed_scripts) folder.